\documentclass[conference]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote.
% If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{TODO Title}
\author{\IEEEauthorblockN{David Carciente}
\IEEEauthorblockA{40247907}
\and
\IEEEauthorblockN{Brian Tkatch}
\IEEEauthorblockA{40191139}
}

\maketitle

%\begin{abstract}
% No abstract is called for by the assignment for this deliverable. It is
% required for the final paper.
%\end{abstract}

\section{Introduction}

Mobile phones are essential to modern life, but selecting a cell phone plan
is a challenging and frustrating experience. Most users of mobile phones are
not "tech people," but one would not get that impression looking at the
website of a Canadian wireless carrier. These websites are defined by large
pricing matrices, confusing add-ons, technical jargon, and a poor user
experience.

In recent years, and due in large part to advancements in large language
model (LLM) technology, chatbots have seen significant growth as a form of
user interface. The number of features that chatbots offer has increased
and consumers have become more accustomed to using them. Chatbots offer
instant service and a universally-accessible experience for users who may
not find phone calls or in-person visits accessible.
TODO CITATION NEEDED HERE - it would be nice to say something like X\% of
users or X\% growth in users willing to use a chatbot or having a good
experience with one.

\subsection{Hypothesis}

We believe that reimplementing the websites of mobile carriers with a
chatbot-based mobile plan selection experience will result in higher user
satisfaction and a shorter amount of time spent on the mobile plan selection
process.

\subsection{Motivation}

The poor user experience of the existing wireless plan selection process is
to the detriment of not just the user, but the carrier as well. Research
indicates that customer satisfaction in Canada's wireless industry lags
significantly behind other consumer industries and the wireless industries in
other countries [TODO CITE 2 OF PROPOSAL].

The plan selection process is necessarily adversarial. The carrier wants to
maximize recurring revenue and the user wants to avoid spending more than
necessary. But the process does not have to \emph{feel} that way. An
adversarial relationship is hardly a baseline for future business. Chatbots
can offer the user a personal experience and make the user feel that the bot
is on their side, at a low cost. [TODO INSERT RESEARCH ON CHATBOTS AND
EMOTIONAL BONDS] Research indicates that the main reasons users leave a
mobile carrier are cost-related [TODO CITE 3 OF PROPOSAL].
Being continuously competitive on cost and perceived value to the user is
therefore important to carriers.

\section{Background}

TODO David to work on this part - include the image of the Rogers thing and
plenty of images in general to beef it up to the 5-6 pages they ask for

We can also do a bit on chatbots, chatbot growth/uptake, and show some
chatbot user interface screenshots (remember that how Joonbot works is
not free text)


Within this part we need to cite some more studies in addition to the two
that were already cited in the proposal.


The content of the paragraphs below should be kept in some form.

Our audience is Canadian mobile phone users. This is a very large audience
(TODO INSERT CITE OF HOW MANY MOBILE USERS IN CANADA) and there are a few
distinct sub-categories.

The first sub-category is users who have recently purchased a mobile plan or
switched carriers (within the last 18 months) and who affirm that they remember
how they experienced the process. The second is mobile phone users who pay for
their own plan but did not purchase it recently. The third is mobile phone users
who do not currently pay for their own plan but who might need to in the future.
This could include people who currently enjoy a phone paid for by an employer or
as part of a family plan.

Each of these sub-categories of the audience arrives at the user interface
with different levels of sophistication, different biases, and different lived
experiences. While the detailed description of personas is beyond the scope of
a conference paper, members of these three sub-categories would form the basis
of personas used in the interface design process.

\section{Methods}

We will first analyze the pricing structure of an existing carrier --- to
preserve the integrity of the research, the prices and features proposed to the
user must be the same in both experiences.

Before programming a chatbot, we will first develop the list of questions to
which the chatbot must obtain answers from the user. These questions include
(but are not limited to):

\begin{itemize}
    \item the user's personal information, such as name and region
    \item information about the user's mobile usage, such as app habits and
          hours of use per day (to estimate the user's data usage in a
          user-friendly manner)
    \item information about the user's travel habits (to determine the need
          for roaming features)
    \item whether the user is also looking to purchase or finance a device,
          and if so, information about their preferences for the new device.
\end{itemize}

We will then program a chatbot experience that will guide the user through
these questions. As an affordance to the user, some questions will have suggested
answers proposed to the user, to keep them on track and minimize the time spent.

The chatbot experience will be implemented using a commercial chatbot product
which is based on web technologies. We plan to implement a full-window chatbot
experience.

Finally, once the chatbot experience has concluded, we will redirect the user
to a custom-built web page that explains the details of the plan the chatbot
selected from them and the reasons why the plan is suitable for them.

\section{Evaluation}

TODO DAVID TO BEEF UP THIS SECTION IF NECCESARY

In general, to evaluate the design of a user interface, it is necessary to
test the design with people who represent real users and who are not involved
in the design process (so as not to be biased).

As discussed in the Background section, our audience is large, and there are
three distinct sub-categories. The interface must be well-adapted to all of
them without explicit advance knowledge of who will be using it. In other
words, it must be universally accessible.

We will evaluate the user interface by comparative user testing against
existing carrier websites. For users who purchased a plan within the last
18 months, we will ask them to refer to their lived experience as they
remember it. For other users, we will refer them to a carrier website and ask
them to identify the plan they would buy. We would then have the user interact
with the chatbot.

We will collect qualitative and quantitative data. For all users, we will
measure the time spent conversing with the chatbot. For users who did not
recently purchase a chatbot, we will also measure the time spent on the carrier
website to choose a plan.

When the user finishes interacting with the chatbot, we will provide the user
with a questionnaire. The questionnaire will first collect an open-ended answer
to which experience the user preferred and why. The questionnaire will then
ask the user to rate each experience on a likert scale in response to
specific questions, including:

\begin{itemize}
    \item whether they found the interface easy to use
    \item whether they felt the plan they chose met their needs
    \item whether they felt they understood the features of the plan they
          selected
    \item whether they got a positive impression of the carrier based on the
          plan selection experience
    \item whether they believe they got the best value for the money
\end{itemize}

After the likert questions, we will provide the user an additional opportunity
to provide open-ended feedback. The open-ended feedback will be classified for
analysis purposes as favourable to the chatbot, favourable to the existing
website, or neutral.

The likert data, the classification of the open-end feedback, and as a
secondary metric, the time spent, will form the basis for numerical hypothesis
testing.

\section{Risks}

The primary risk to the project is the very short timeframe on which it is to be completed --- just three weeks after the submission of this research paper. The primary mitigation of this risk is 

Technical risks are mostly derivative from timeframe risks, in that there is no
belief that the project is technically infeasible. It is only the
previously-discussed question on whether the technical project can be delivered
on time.

Evaluation risks are also derivative from timeframe risks, in so far as the short
timeframe may make it difficult to find a sufficient number of candidates and
complete the study with those candidates, because the study can only be completed
after the product is developed. This may result in the data failing to attain
statistical significance due to an insufficient sample size. Statistical setbacks,
however, are an inherent part of the experimental process --- one would not
perform an experiment if the result was known ahead of time.

TODO INSERT ACTUAL CITATIONS IN THE BIB AND IN THE TEXT

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\bibitem{b8} D. P. Kingma and M. Welling, ``Auto-encoding variational Bayes,'' 2013, arXiv:1312.6114. [Online]. Available: https://arxiv.org/abs/1312.6114
\bibitem{b9} S. Liu, ``Wi-Fi Energy Detection Testbed (12MTC),'' 2023, gitHub repository. [Online]. Available: https://github.com/liustone99/Wi-Fi-Energy-Detection-Testbed-12MTC
\bibitem{b10} ``Treatment episode data set: discharges (TEDS-D): concatenated, 2006 to 2009.'' U.S. Department of Health and Human Services, Substance Abuse and Mental Health Services Administration, Office of Applied Studies, August, 2013, DOI:10.3886/ICPSR30122.v2
\bibitem{b11} K. Eves and J. Valasek, ``Adaptive control for singularly perturbed systems examples,'' Code Ocean, Aug. 2023. [Online]. Available: https://codeocean.com/capsule/4989235/tree
\end{thebibliography}

\end{document}
